<!DOCTYPE html>
<html>
<head>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-49TJQWLWDQ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-49TJQWLWDQ');
  </script>

  <meta charset="utf-8">
  <meta name="description" content="GLARE: A Natural Language Interface for Querying Global Explanations">
  <meta name="keywords" content="explainable AI, XAI, global explanations, natural language interface, LLM, text-to-SQL, GLARE">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GLARE: A Natural Language Interface for Querying Global Explanations</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <link rel="icon" href="./resources/favicon.ico">

  <script src="https://kit.fontawesome.com/006a5775d5.js" crossorigin="anonymous"></script>
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

  <style>
    /* --- Accordion Dropdown Styles --- */
    .section-toggle {
        font-size: 0.8rem;
        font-weight: normal;
        cursor: pointer;
        color: #3273dc;
        margin-left: 15px;
        vertical-align: middle;
        text-decoration: none;
    }
    .section-toggle:hover {
        text-decoration: underline;
    }

    .dropdown-item {
        margin-bottom: 1rem;
    }

    .dropdown-header {
        font-size: 1.1rem;
        font-weight: 600;
        cursor: pointer;
        padding: 15px 20px;

        display: flex;
        align-items: center;
        justify-content: space-between;

        background-color: #ffffff;
        border: 1px solid #dbdbdb;
        border-radius: 5px;
        box-shadow: 0 3px 5px rgba(0,0,0,0.03);

        transition: all 0.2s ease-in-out;
    }

    .dropdown-header:hover {
        background-color: #f9f9f9;
        box-shadow: 0 5px 8px rgba(0,0,0,0.05);
        transform: translateY(-2px);
    }

    .header-text {
        flex-grow: 1;
        padding-right: 15px;
        word-break: break-word;
    }

    .dropdown-header .icon {
        flex-shrink: 0;
        transition: transform 0.2s ease-in-out;
        font-size: 1rem;
        color: #7a7a7a;
    }

    .dropdown-header.active .icon {
        transform: rotate(180deg);
    }
    .dropdown-header.active {
        background-color: #f5f5ff;
        border-bottom-left-radius: 0;
        border-bottom-right-radius: 0;
    }

    .dropdown-content {
        display: none;
        padding: 20px 25px;
        background-color: #ffffff;
        border: 1px solid #dbdbdb;
        border-top: none;

        margin-top: -1px;
        border-radius: 0 0 5px 5px;

        margin-left: 0;
        border-left: none;
    }
    .dropdown-content p, .dropdown-content ul {
        font-size: 1rem;
        line-height: 1.6;
        white-space: normal;
        word-break: break-word;
    }

    pre, code {
        white-space: pre-wrap;
        word-break: break-all;
    }

    .visible-image {
        margin: 20px auto;
        display: block;
        max-width: 100%;
        border: 1px solid #ddd;
        border-radius: 4px;
        padding: 5px;
    }

    img {
        max-width: 100%;
        height: auto;
    }

    .global-toggle-container {
        text-align: center;
        padding: 10px 0;
    }

    /* Results table styles */
    .results-table-container {
        overflow-x: auto;
        margin: 25px 0;
    }
    .results-table {
        width: 100%;
        min-width: 700px;
        border-collapse: collapse;
        font-size: 0.85rem;
    }
    .results-table th, .results-table td {
        border: 1px solid #dbdbdb;
        padding: 8px 10px;
        text-align: center;
        vertical-align: middle;
    }
    .results-table th {
        background-color: #f5f5f5;
        font-weight: 600;
    }
    .results-table .model-col {
        text-align: left;
        font-weight: 600;
        min-width: 120px;
    }
    .results-table .setting-col {
        font-weight: 600;
    }

    /* Color coding for metrics */
    .c-high { background-color: #00A3A1; color: white; }
    .c-med { background-color: #64D1C6; }
    .c-low { background-color: #C8F1EA; }

    .p-high { background-color: #BBA0E5; }
    .p-med { background-color: #DCC4F6; }
    .p-low { background-color: #F4EBFC; }

    .results-table .c-high strong { color: white !important; }

    .table-caption {
        font-size: 0.9rem;
        font-style: italic;
        color: #555;
        margin-bottom: 10px;
        text-align: left;
    }

    .header-baselines { background-color: #ffcccc !important; }
    .header-main { background-color: #ccffcc !important; }
    .header-transfer { background-color: #cceeff !important; }

    /* Results Charts Styles */
    .results-chart-container {
        margin: 20px 0;
        padding: 25px;
        background: #fafafa;
        border-radius: 12px;
    }
    .chart {
        display: flex;
        flex-direction: column;
        gap: 8px;
    }
    .chart-row {
        display: flex;
        align-items: center;
        gap: 10px;
    }
    .chart-label {
        width: 160px;
        font-size: 0.85em;
        font-weight: 600;
        color: #444;
        text-align: right;
        flex-shrink: 0;
    }
    .chart-bar-container {
        flex: 1;
        height: 28px;
        background: #eee;
        border-radius: 4px;
        position: relative;
        overflow: hidden;
    }
    .chart-bar {
        height: 100%;
        border-radius: 4px;
        display: flex;
        align-items: center;
        justify-content: flex-end;
        padding-right: 8px;
        font-size: 0.75em;
        font-weight: 700;
        color: white;
        transition: width 0.5s;
    }
    .chart-bar.small-text {
        justify-content: flex-start;
        padding-left: 8px;
        color: #333;
    }
    .difficulty-section {
        margin-bottom: 20px;
    }
    .difficulty-header {
        font-weight: 700;
        font-size: 0.9em;
        color: #555;
        margin: 15px 0 8px 0;
        padding: 4px 10px;
        background: #f0f0f0;
        border-radius: 4px;
        display: inline-block;
    }
    .chart-title {
        text-align: center;
        margin-bottom: 20px;
    }
    .chart-title h3 {
        font-size: 1.1em;
        color: #333;
        margin: 0;
    }
    .chart-title p {
        font-size: 0.8em;
        color: #888;
        margin: 4px 0 0;
    }
    .chart-caption {
        font-size: 0.8em;
        color: #777;
        margin-top: 15px;
        text-align: center;
        font-style: italic;
    }
    .chart-divider {
        border-top: 1px solid #ddd;
        margin: 8px 0 8px 170px;
    }

    /* Pipeline SVG styles */
    .pipeline-container {
        margin: 20px auto;
        max-width: 860px;
        background: white;
        border: 1px solid #ddd;
        border-radius: 8px;
        padding: 20px;
    }

    /* Query example styles */
    .query-example {
        background: #f8f9fa;
        border-left: 4px solid #3273dc;
        padding: 15px 20px;
        margin: 15px 0;
        border-radius: 0 6px 6px 0;
    }
    .query-example .query-q {
        font-weight: 600;
        color: #3273dc;
        margin-bottom: 5px;
    }
    .query-example .query-a {
        color: #2d6a2e;
        font-style: italic;
    }
    .query-example code {
        background: #e9ecef;
        padding: 2px 6px;
        border-radius: 3px;
        font-size: 0.88em;
    }

    /* Taxonomy node styles */
    .taxonomy-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 15px;
        margin: 20px 0;
    }
    .taxonomy-card {
        background: white;
        border: 1px solid #dbdbdb;
        border-radius: 8px;
        padding: 15px;
    }
    .taxonomy-card h4 {
        margin: 0 0 8px 0;
        font-size: 0.95em;
        padding-bottom: 6px;
        border-bottom: 2px solid;
    }
    .taxonomy-card.core h4 { color: #2980b9; border-color: #d4e6f1; }
    .taxonomy-card.extended h4 { color: #27ae60; border-color: #d5f5e3; }
    .taxonomy-card.contrastive h4 { color: #e67e22; border-color: #fdebd0; }
    .taxonomy-card ul {
        list-style: none;
        padding: 0;
        margin: 0;
    }
    .taxonomy-card li {
        font-size: 0.85em;
        padding: 3px 0;
        color: #555;
    }

    @media (max-width: 768px) {
        .taxonomy-grid {
            grid-template-columns: 1fr;
        }
    }

  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">GLARE: A Natural Language Interface for Querying Global Explanations</h1>
          <div class="is-size-4 publication-authors">
            <span class="author-block">
              Anonymous Authors
              <br><br>
              Anonymous University
            </span>
          </div>

          <h2 class="is-size-4 has-text-weight-bold has-text-success-dark mt-4 mb-4">
            Transforms global model explanations from static artifacts into queryable databases&mdash;users ask natural language questions and receive structured answers with statistics, examples, and visualizations. Achieves 95% query accuracy, 90.6% zero-shot cross-dataset transfer, and 85% robustness to input perturbations.
          </h2>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section pt-0 pb-4">
    <div class="container global-toggle-container">
      <button id="global-toggle" class="button is-info is-rounded" data-action="expand">Expand All Sections</button>
    </div>
</section>

<section class="section pt-0">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-2 has-text-centered">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Global explanations help users understand how vision models behave across datasets, classes, and decision contexts. However, for modern deep neural networks, global explanations are often complex, voluminous, and difficult for users to meaningfully explore. We present GLARE, an LLM-based interactive explanation interface that enables natural language access to global explanations for black-box image classification models. Users ask natural language questions and receive concise, interpretable responses: natural language summaries with statistics, supporting local explanations, and visualizations aligned with the user's intent. The core of the interface is a large language model fine-tuned to map natural language queries to structured SQL queries over explanation databases. We evaluate the system's ability to accurately interpret user intent, its robustness to spelling errors and grammatical variations, and its generalization to new query types and datasets. Our results show over 95% accuracy on in-distribution queries, 90.6% zero-shot cross-dataset transfer, and 85% robustness to perturbations.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-three-quarters">

        <!-- ============================================================ -->
        <!-- SECTION 1: Why Natural Language for Explanations? -->
        <!-- ============================================================ -->
        <div class="section-container">
            <h2 class="title is-2">Why Natural Language for Explanations?
                <a class="section-toggle" data-action="expand">[Expand All]</a>
            </h2>

            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Global explanations are overwhelming:</b> A single class might have hundreds of logical rules&mdash;too many for any user to digest.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>Modern global explanations for deep neural networks often consist of thousands of logical rules or prototypes. For example, a global explanation for a scene classifier might express that a "bedroom" is recognized via dozens of distinct object combinations: (bed &and; wall), (bed &and; curtain &and; lamp), etc. Presenting this entire "explanation dump" to a user induces cognitive overload and obscures the very insights it aims to reveal.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Users want answers, not artifacts:</b> People approach models with specific questions, not a desire to browse static summaries.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>Human explanation-seeking is an iterative, query-driven process. Users approach models with specific hypotheses: <em>"What features are necessary for the 'bedroom' class?"</em>, <em>"Does the model rely on background snow to classify wolves?"</em>, or <em>"Show me examples where the model relies on shape rather than texture."</em> Current XAI tools force users to manually filter and aggregate explanations to answer these questions.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Dialogue is natural:</b> Explanations are social&mdash;they emerge from interactive dialogue, not monologue.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>Research in social science shows that explanations are inherently interactive. Users naturally ask <em>"Why?"</em>, <em>"Why not?"</em>, and <em>"What if?"</em> questions. Static dashboards fail because they cannot anticipate the specific, context-dependent questions a user might have. A natural language interface aligns with how humans naturally seek and process explanations.</p>
                </div>
            </div>
            <hr>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 2: The Problem with Current XAI -->
        <!-- ============================================================ -->
        <div class="section-container">
            <h2 class="title is-2">The Problem with Current XAI
                <a class="section-toggle" data-action="expand">[Expand All]</a>
            </h2>

            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Local explanations miss the big picture:</b> Saliency maps explain one image but reveal nothing about systematic biases.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>Local methods like Grad-CAM, SHAP, and concept bottleneck models explain specific instances (e.g., "Why was <em>this</em> image classified as a wolf?"). While useful for auditing single errors, they fail to reveal systemic biases, general reasoning patterns, or the diversity of strategies a model uses across a dataset.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Global explanations suffer from information overload:</b> High-fidelity global summaries can contain thousands of rules.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>Global explanations summarize a model's behavior across the entire input space. Methods like decision trees, DNF formulas, or globally important concepts attempt this, but for deep networks trained on complex visual domains, these explanations become massive. Users cannot meaningfully browse or internalize thousands of logical clauses without filtering mechanisms.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Generating explanations with LLMs risks hallucination:</b> Using LLMs to <em>create</em> explanations directly is unfaithful to the model.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>Some approaches use LLMs to directly generate natural language explanations. However, this risks hallucination&mdash;the LLM might produce plausible-sounding but incorrect explanations. GLARE avoids this by using the LLM as a <em>semantic parser</em> that maps questions to deterministic SQL queries. The answers come from the actual explanation data, not from the LLM's imagination.</p>
                </div>
            </div>
            <hr>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 3: GLARE's Key Insight -->
        <!-- ============================================================ -->
        <div class="section-container">
            <h2 class="title is-2">GLARE's Key Insight
                <a class="section-toggle" data-action="expand">[Expand All]</a>
            </h2>

            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Treat explanations as a database, not a document:</b> Global explanations become a queryable relational database, not a static artifact.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>Rather than viewing global explanations as a monolithic artifact to be passively consumed, GLARE ingests local explanations (Minimal Sufficient Explanations expressed as DNF formulas) into a relational database. This enables precise structural queries: frequency counts, co-occurrence analysis, cross-class comparisons, set operations, and counterfactual reasoning&mdash;all through standard SQL.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>LLMs as semantic parsers, not generators:</b> The LLM translates questions into SQL&mdash;answers come from data, not the model.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>The LLM's role is to act as a <em>logic-constrained semantic parser</em>. Given a natural language question, it selects from a taxonomy of SQL query templates and extracts the relevant parameters (class names, object names, thresholds). The SQL is then executed against the explanation database deterministically. This ensures formal correctness: the flexibility of natural language does not come at the cost of accuracy.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Synthetic training enables zero-shot transfer:</b> Train on auto-generated data from one dataset, deploy on any new domain without retraining.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>A key technical challenge is enabling deployment on new datasets without expensive manual annotation. GLARE generates 50,000 synthetic training examples from schema metadata alone. A "fence masking" technique during fine-tuning focuses learning exclusively on SQL structure (not entity names), teaching the model the <em>relational algebra</em> of explanation querying. This enables zero-shot transfer&mdash;a model trained on ADE20K transfers directly to Pascal VOC (a completely different object vocabulary) at 90.6% accuracy.</p>
                </div>
            </div>

            <!-- Example queries -->
            <div class="query-example">
                <div class="query-q">"What percentage of bedroom images contain both bed and wall?"</div>
                <div class="query-a">GLARE &rarr; SQL query &rarr; "73.2% of bedroom images contain both bed and wall." + supporting evidence images with highlighted objects</div>
            </div>
            <div class="query-example">
                <div class="query-q">"Which objects distinguish kitchen from dining room?"</div>
                <div class="query-a">GLARE &rarr; SQL set difference &rarr; "Objects found in kitchen but not dining room: stove (82%), oven (61%), range hood (43%)..." + example images</div>
            </div>
            <hr>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 4: System Overview -->
        <!-- ============================================================ -->
        <div class="section-container">
            <h2 class="title is-2">System Overview
                <a class="section-toggle" data-action="expand">[Expand All]</a>
            </h2>

            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Parse-Validate-Execute pipeline:</b> Questions flow through LLM parsing, SQL validation, database execution, and multimodal response.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>The system follows a structured pipeline: (1) A user poses a question in natural language. (2) The fine-tuned LLM translates it into a SQL query by selecting from predefined templates and extracting parameters. (3) The SQL is validated for correctness and safety. (4) The query is executed against the explanation database. (5) Results are returned as structured data along with a natural language summary, statistics, and supporting evidence images with highlighted objects.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>LLM-based query interpretation:</b> Gemma 2-9B fine-tuned with QLoRA and fence-based loss masking for SQL generation.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>We fine-tune Gemma 2-9B using QLoRA (4-bit quantization, LoRA rank 16). The model receives a system prompt with the database schema and available query templates, a user prompt with the question and allowed entity names, and generates SQL between <code>SQL_START</code> and <code>SQL_END</code> fence markers. During fine-tuning, a custom "fence-based loss masking" technique ignores all prompt tokens and focuses learning exclusively on the SQL generation tokens.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>24 query templates in 3 tiers:</b> Core, Extended, and Contrastive queries covering frequency, co-occurrence, set operations, and counterfactual analysis.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>The query templates are organized into three tiers of increasing complexity. Adding a new question type requires only defining a new SQL pattern and regenerating synthetic data&mdash;no manual annotation needed.</p>

                    <div class="taxonomy-grid">
                        <div class="taxonomy-card core">
                            <h4>Core Queries</h4>
                            <ul>
                                <li>Object frequency (%)</li>
                                <li>Boolean: AND, OR, NOT</li>
                                <li>Top-k / Bottom-k ranking</li>
                                <li>Co-occurrence with anchor</li>
                                <li>Class ranking for object</li>
                            </ul>
                        </div>
                        <div class="taxonomy-card extended">
                            <h4>Extended Queries</h4>
                            <ul>
                                <li>N-way combos (self-joins)</li>
                                <li>Cross-class comparison</li>
                                <li>Set difference / intersection</li>
                                <li>Conditional co-occurrence</li>
                                <li>Confidence-filtered analysis</li>
                            </ul>
                        </div>
                        <div class="taxonomy-card contrastive">
                            <h4>Contrastive Queries</h4>
                            <ul>
                                <li>Absence analysis</li>
                                <li>Threshold queries</li>
                                <li>Distinguishing features</li>
                                <li>Counterfactual reasoning</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Multimodal output:</b> Each response includes natural language, statistics, and evidence images with highlighted objects.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>For each query, GLARE returns three types of output: (1) A natural language summary with relevant statistics (e.g., "Sculptures in living rooms most often appear with walls (80%) followed by sofas (60%)"). (2) Supporting local explanation examples. (3) Visualizations aligned with the user's intent&mdash;including evidence images showing original images, important objects identified by local explanations, and masked images highlighting only the relevant objects.</p>
                </div>
            </div>
            <hr>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 5: Results -->
        <!-- ============================================================ -->
        <div class="section-container">
            <h2 class="title is-2">Results
                <a class="section-toggle" data-action="expand">[Expand All]</a>
            </h2>

            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>95.2% in-distribution accuracy:</b> Fine-tuned models achieve near-perfect structural metrics and high result-match rates.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>On 500 held-out test queries, Gemma 2-9B achieves 100% fence detection, 100% SQL parse rate, 100% execution rate, and 95.2% result-match accuracy. An additional 2.4% of examples achieve partial matches (Jaccard > 0.5), bringing effective accuracy above 97%. Performance saturates across model scales: Gemma 2 at 2B, 9B, and 27B all achieve ~95% accuracy.</p>
                    <p><strong>Base models (without fine-tuning) achieve near-zero accuracy</strong>, confirming that our synthetic training pipeline is essential&mdash;not just pre-existing SQL knowledge.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>100% accuracy on 18 of 25 query types:</b> Perfect performance on percentages, ranking, co-occurrence, set operations, and more.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>The per-query-type breakdown shows 100% accuracy on 18 of 25 evaluated query types, spanning percentage calculations, top-k ranking, co-occurrence joins, set operations, conditional existence checks, threshold filtering, and statistical aggregations. The two underperforming types (<code>combos</code> at 49% and <code>images_with_exact_count</code> at 43%) involve complex multi-way self-joins and exact-count HAVING clauses.</p>
                </div>
            </div>

            <!-- ACCURACY COMPARISON CHART -->
            <div class="results-chart-container">
                <div class="chart-title">
                    <h3>In-Distribution Result-Match Accuracy (%)</h3>
                    <p>Fine-tuned models on ADE20K Fresh Test set (500 examples)</p>
                </div>

                <div class="chart">
                    <div class="chart-row">
                        <div class="chart-label">Gemma 2 (9B) FT</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 95.2%; background: #00A3A1;">95.2%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Gemma 2 (27B) FT</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 95.2%; background: #2ab8b6;">95.2%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Gemma 2 (2B) FT</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 95.4%; background: #4dc9c7;">95.4%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Qwen 2.5 (14B) FT</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 95.4%; background: #7ab8b6;">95.4%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Qwen 2.5 (7B) FT</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 93%; background: #9ec5c4;">93.0%</div></div>
                    </div>
                    <div class="chart-divider" style="margin-left:0"></div>
                    <div class="chart-row">
                        <div class="chart-label" style="color:#c0392b;">Gemma 2 (9B) Base</div>
                        <div class="chart-bar-container"><div class="chart-bar small-text" style="width: 2%; background: #e74c3c;">0.2%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label" style="color:#c0392b;">Qwen 2.5 (7B) Base</div>
                        <div class="chart-bar-container"><div class="chart-bar small-text" style="width: 4%; background: #c0392b;">3.2%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label" style="color:#c0392b;">Qwen 2.5 (0.5B) FT</div>
                        <div class="chart-bar-container"><div class="chart-bar small-text" style="width: 5%; background: #922b21;">4.4%</div></div>
                    </div>
                </div>
                <p class="chart-caption">Fine-tuned models achieve ~95% accuracy across scales. Base models score near 0%, confirming the value of synthetic training. A minimum model capacity (~2B+ params) is required.</p>
            </div>

            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Robust to input perturbations:</b> 100% robustness to synonyms, 97% to verbose padding, 89% to spelling errors.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>The model is tested against 7 perturbation types: synonym substitution (100% robustness), verbose padding (97%), spelling errors (89%), telegraphic compression (84%), word swap (82%), grammar corruption (76%), and word drop (48%). Word drop is inherently damaging&mdash;removing object or class names destroys the information needed for correct SQL. Paraphrase consistency reaches 94.1%, and all sanity checks pass (100%).</p>
                </div>
            </div>

            <!-- ROBUSTNESS CHART -->
            <div class="results-chart-container">
                <div class="chart-title">
                    <h3>Robustness to Input Perturbations</h3>
                    <p>% of baseline accuracy preserved under each perturbation (Gemma 2-9B)</p>
                </div>

                <div class="chart">
                    <div class="chart-row">
                        <div class="chart-label">Synonym substitution</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 100%; background: #27ae60;">100%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Verbose padding</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 97%; background: #2ecc71;">97%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Spelling errors</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 89%; background: #f39c12;">89%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Telegraphic</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 84%; background: #e67e22;">84%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Word swap</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 82%; background: #e67e22;">82%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Grammar corruption</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 76%; background: #e74c3c;">76%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Word drop</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 48%; background: #c0392b;">48%</div></div>
                    </div>
                </div>
                <p class="chart-caption">The learned SQL mapping is largely invariant to lexical and syntactic surface variation. Word drop is inherently destructive&mdash;removing entity names eliminates the information needed for correct SQL.</p>
            </div>

            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Zero-shot cross-dataset transfer at 90.6%:</b> Trained on ADE20K, tested on Pascal VOC with a completely different vocabulary&mdash;no retraining.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>The model, trained exclusively on ADE20K entity names (150 objects, 20 scene classes), is tested on a database built from Pascal VOC (166 objects, different scene taxonomy). Gemma 2-27B achieves 90.6% result-match accuracy with perfect structural metrics. This is the strongest evidence that the model learns generalizable <em>relational structure</em>&mdash;SQL's compositionality separates query structure from vocabulary, enabling deployment on any new database without retraining.</p>
                </div>
            </div>

            <!-- CROSS-DATASET CHART -->
            <div class="results-chart-container">
                <div class="chart-title">
                    <h3>Cross-Dataset Transfer: ADE20K &rarr; Pascal VOC</h3>
                    <p>Models trained on ADE20K, tested on Pascal VOC (completely different object vocabulary)</p>
                </div>

                <div class="chart">
                    <div class="chart-row">
                        <div class="chart-label">Gemma 2 (27B)</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 90.6%; background: #2980b9;">90.6%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Gemma 2 (2B)</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 90%; background: #3498db;">90.0%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Qwen 2.5 (14B)</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 90%; background: #5dade2;">90.0%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Gemma 2 (9B)</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 89.6%; background: #85c1e9;">89.6%</div></div>
                    </div>
                    <div class="chart-row">
                        <div class="chart-label">Qwen 2.5 (7B)</div>
                        <div class="chart-bar-container"><div class="chart-bar" style="width: 87.2%; background: #aed6f1;">87.2%</div></div>
                    </div>
                </div>
                <p class="chart-caption">The model learns SQL's compositional structure, not dataset-specific entity associations. Even 2B-parameter models transfer at 90%.</p>
            </div>

            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>OOD generalization:</b> 45% on novel phrasing, 100% on some emergent compositions, graceful degradation on unseen SQL.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>Out-of-distribution evaluation probes two aspects: (1) Novel phrasing of trained patterns (45.1% match)&mdash;the model handles nested questions (90%), negations (70%), and zero-threshold queries (100%), but struggles with informal language (12%) and double negation (0%). (2) Novel SQL constructs absent from training (19.5% match)&mdash;chained filters (100%) and string patterns (100%) work via compositional generalization, while window functions and CASE expressions (0%) confirm the model cannot extrapolate to truly novel SQL syntax. Critically, even on unsupported constructs, the model maintains 99.3% execution rate by falling back to the closest known template&mdash;graceful degradation.</p>
                </div>
            </div>

            <!-- Detailed Tables -->
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>View Full Results Table:</b> All models, base vs. fine-tuned, across all evaluation axes
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <div class="table-caption">
                        <b>In-distribution performance</b> on the ADE20K Fresh Test set (500 examples).
                    </div>
                    <div class="results-table-container">
                        <table class="results-table">
                            <thead>
                                <tr>
                                    <th class="model-col">Model</th>
                                    <th class="setting-col">Setting</th>
                                    <th>Fence %</th>
                                    <th>Parse %</th>
                                    <th>Execute %</th>
                                    <th>Match %</th>
                                    <th>Partial %</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td class="model-col">Gemma 2 (2B)</td><td class="setting-col">base</td>
                                    <td>71.2</td><td>6.2</td><td>6.2</td><td>0.0</td><td>0.4</td>
                                </tr>
                                <tr>
                                    <td class="model-col">Gemma 2 (2B)</td><td class="setting-col">fine-tuned</td>
                                    <td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>95.4</strong></td><td>2.8</td>
                                </tr>
                                <tr><td colspan="7" style="background-color: #fafafa; height: 3px; border: 0;"></td></tr>
                                <tr>
                                    <td class="model-col">Gemma 2 (9B)</td><td class="setting-col">base</td>
                                    <td>100</td><td>3.2</td><td>3.2</td><td>0.2</td><td>0.4</td>
                                </tr>
                                <tr>
                                    <td class="model-col">Gemma 2 (9B)</td><td class="setting-col">fine-tuned</td>
                                    <td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>95.2</strong></td><td>2.4</td>
                                </tr>
                                <tr><td colspan="7" style="background-color: #fafafa; height: 3px; border: 0;"></td></tr>
                                <tr>
                                    <td class="model-col">Gemma 2 (27B)</td><td class="setting-col">base</td>
                                    <td>100.0</td><td>0.6</td><td>0.6</td><td>0.0</td><td>0.2</td>
                                </tr>
                                <tr>
                                    <td class="model-col">Gemma 2 (27B)</td><td class="setting-col">fine-tuned</td>
                                    <td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>95.2</strong></td><td>3.0</td>
                                </tr>
                                <tr><td colspan="7" style="background-color: #fafafa; height: 3px; border: 0;"></td></tr>
                                <tr>
                                    <td class="model-col">Qwen 2.5 (0.5B)</td><td class="setting-col">fine-tuned</td>
                                    <td>93.8</td><td>4.6</td><td>4.6</td><td>4.4</td><td>0.0</td>
                                </tr>
                                <tr>
                                    <td class="model-col">Qwen 2.5 (7B)</td><td class="setting-col">fine-tuned</td>
                                    <td class="c-high"><strong>100.0</strong></td><td class="c-med">97.6</td><td class="c-med">97.6</td><td class="c-high"><strong>93.0</strong></td><td>3.0</td>
                                </tr>
                                <tr>
                                    <td class="model-col">Qwen 2.5 (14B)</td><td class="setting-col">fine-tuned</td>
                                    <td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>100.0</strong></td><td class="c-high"><strong>95.4</strong></td><td>2.6</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>

                    <div class="table-caption" style="margin-top: 25px;">
                        <b>Cross-model comparison</b> across all evaluation axes.
                    </div>
                    <div class="results-table-container">
                        <table class="results-table">
                            <thead>
                                <tr>
                                    <th class="model-col">Model</th>
                                    <th>Params</th>
                                    <th>Fresh %</th>
                                    <th>OOD %</th>
                                    <th>Pascal %</th>
                                    <th>Robust %</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td class="model-col">Gemma 2</td><td>2B</td>
                                    <td class="c-high"><strong>95.4</strong></td><td>30.3</td><td class="c-high"><strong>90.0</strong></td><td class="c-med">78.9</td>
                                </tr>
                                <tr>
                                    <td class="model-col">Gemma 2</td><td>9B</td>
                                    <td class="c-high"><strong>95.2</strong></td><td>35.0</td><td class="c-med">89.6</td><td class="c-med">82.8</td>
                                </tr>
                                <tr>
                                    <td class="model-col">Gemma 2</td><td>27B</td>
                                    <td class="c-high"><strong>95.2</strong></td><td>34.3</td><td class="c-high"><strong>90.6</strong></td><td class="c-med">85.9</td>
                                </tr>
                                <tr><td colspan="6" style="background-color: #fafafa; height: 3px; border: 0;"></td></tr>
                                <tr>
                                    <td class="model-col">Qwen 2.5</td><td>0.5B</td>
                                    <td>4.4</td><td>4.7</td><td>4.4</td><td class="p-low">54.4</td>
                                </tr>
                                <tr>
                                    <td class="model-col">Qwen 2.5</td><td>7B</td>
                                    <td class="c-high"><strong>93.0</strong></td><td class="p-low"><strong>40.0</strong></td><td class="c-med">87.2</td><td class="c-med">82.2</td>
                                </tr>
                                <tr>
                                    <td class="model-col">Qwen 2.5</td><td>14B</td>
                                    <td class="c-high"><strong>95.4</strong></td><td class="p-low"><strong>40.0</strong></td><td class="c-high"><strong>90.0</strong></td><td class="c-med">82.5</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </div>
            </div>
            <hr>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 6: Case Studies -->
        <!-- ============================================================ -->
        <div class="section-container">
            <h2 class="title is-2">Case Studies
                <a class="section-toggle" data-action="expand">[Expand All]</a>
            </h2>

            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>End-to-end multimodal response:</b> Co-occurrence query produces NL summary, statistics, and visual grounding.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <div class="query-example">
                        <div class="query-q">"In living_room, what objects appear with sculpture?"</div>
                        <div class="query-a">"Sculptures in living rooms most often appear with walls (80% of the time), followed by sofas (60%). Other common objects found alongside sculptures include cushions, coffee tables, and windowpanes."</div>
                    </div>
                    <p>The system generates a complex co-occurrence SQL query with correlated subquery, executes it, and returns a multi-modal response: fluent NL summary, quantitative statistics (wall 80%, sofa 60%, cushion 53%...), and top-3 evidence images showing original images, important objects, and masked highlights.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Character-identical SQL on held-out queries:</b> Novel entity combinations produce exact SQL matches.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <div class="query-example">
                        <div class="query-q">"What % of corridor images with probability at least 0.7 contain stool?"</div>
                        <div class="query-a">"About 0.14% of corridor images with a probability of at least 0.7 contain a stool."</div>
                    </div>
                    <p>The predicted SQL is <em>character-for-character identical</em> to the gold standard. This is not an isolated case&mdash;it holds for existence checks, probability-filtered queries, and many more. The model has internalized SQL's compositional structure as reusable rules rather than memorized surface strings: the specific entity names (<code>stool</code>, <code>corridor</code>, <code>0.7</code>) never co-occur in training.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Cross-dataset transfer with 4-way self-joins:</b> Pascal VOC body-part vocabulary produces perfect SQL on first try.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <div class="query-example">
                        <div class="query-q">"Rarest 4-object pairs in aeroplane?"</div>
                        <div class="query-a">"The rarest 4-object pairs in aeroplane images are 'lear', 'torso', 'body', and either 'rhand', 'rlarm', or 'ruarm', each appearing only 2 times."</div>
                    </div>
                    <p>The model, trained on ADE20K with objects like <code>wall</code> and <code>bed</code>, produces a character-identical 4-way self-join query over Pascal VOC body-part vocabulary (<code>lear</code>, <code>torso</code>, <code>rhand</code>) it has never seen. The critical ordering constraint <code>io1.object_id < io2.object_id < io3.object_id < io4.object_id</code> that prevents duplicate combinations is reproduced exactly.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Graceful failure modes:</b> Informal language causes template mis-routing, not crashes. Double negation is unsupported but handled safely.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <div class="query-example">
                        <div class="query-q">"yo how many street pics got water in them"</div>
                        <div class="query-a">"There are 13 street pictures that contain water." (Returns count instead of intended percentage&mdash;correct entity extraction, wrong template selection)</div>
                    </div>
                    <div class="query-example">
                        <div class="query-q">"What percentage of conference_room images are not without screen?"</div>
                        <div class="query-a">"97.38% of conference room images do not show a screen." (Treats double negation as single negation&mdash;returns 97.38% instead of 1.20%)</div>
                    </div>
                    <p>Failure modes are well-characterized: <em>parameter-level errors</em> (incorrect thresholds in ambiguous cases), <em>template mis-routing under register shift</em> (informal language maps to wrong template), and <em>pragmatic reasoning failures</em> (double negation). All are addressable through the same lightweight pipeline: adding templates or phrasing styles requires only updating the synthetic data generator.</p>
                </div>
            </div>
            <hr>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 7: Technical Details -->
        <!-- ============================================================ -->
        <div class="section-container">
            <h2 class="title is-2">Technical Details
                <a class="section-toggle" data-action="expand">[Expand All]</a>
            </h2>

            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Training setup:</b> 50,000 synthetic examples, QLoRA fine-tuning, fence-based loss masking on SQL tokens only.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>Training examples are generated synthetically by sampling from 24 query templates. Each template produces a (natural-language question, SQL query) pair by randomly selecting objects and scene classes from the ADE20K vocabulary. We generate 50,000 training pairs and 2,000 validation pairs. During fine-tuning, the <code>SqlFenceCollator</code> masks the training loss to only tokens between <code>SQL_START</code> and <code>SQL_END</code>, focusing learning exclusively on SQL generation.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Architecture:</b> Gemma 2-9B with LoRA rank 16, alpha 32, targeting all attention and MLP projections.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>We fine-tune Gemma 2-9B using Low-Rank Adaptation (LoRA) with 4-bit quantization (QLoRA). Configuration: LoRA rank 16, alpha 32, dropout 0.05. Targets: all attention projections (q, k, v, o) and MLP projections (gate, up, down). The same configuration is applied across all model sizes (2B, 9B, 27B for Gemma; 0.5B, 7B, 14B for Qwen).</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Explanation database:</b> Built from mDNF explanations of a VGG19 model on ADE20K (150 objects, 35 scene classes).
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>The reference database is built from monotonic Disjunctive Normal Form (mDNF) explanations of a VGG19 classifier computed over the ADE20K dataset. Each class's explanation is a disjunction of conjunctions, where each conjunction is a Minimal Sufficient Explanation (MSX)&mdash;a minimal set of objects whose presence is sufficient for classification. The system can accommodate any local explanation algorithm that generates explanations in symbolic form.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Evaluation metrics:</b> Fence detection, SQL parse rate, execution rate, result match (relaxed), and partial match (Jaccard).
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>We evaluate generated SQL by executing it against the ground-truth database. <strong>Fence Detection</strong>: correct SQL_START/SQL_END delimiters. <strong>SQL Parse Rate</strong>: syntactically valid SQL. <strong>Execution Rate</strong>: runs without error. <strong>Result Match</strong>: relaxed matching (tolerates row-order, LIMIT differences, extra columns, and 1% numeric tolerance). <strong>Partial Match</strong>: Jaccard similarity > 0.5 on first-column values. Additional robustness metrics include robustness score, consistency rate, and sanity pass rate.</p>
                </div>
            </div>
            <hr>
        </div>

        <!-- ============================================================ -->
        <!-- SECTION 8: Why This Matters -->
        <!-- ============================================================ -->
        <div class="section-container">
            <h2 class="title is-2">Why This Matters
                <a class="section-toggle" data-action="expand">[Expand All]</a>
            </h2>

            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>From browsing to questioning:</b> Shifts the cognitive burden from scanning complex formulas to asking targeted questions.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>Instead of manually scanning complex DNF formulas to find relevant patterns, users can ask targeted contrastive questions&mdash;"Does bed always co-occur with wall?" or "Which objects distinguish kitchen from dining room?"&mdash;aligning with the natural human tendency to seek explanations through selective hypothesis testing.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Iterative sensemaking through composition:</b> Users start with broad queries and progressively drill down into specifics.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>The template taxonomy supports progressive exploration: start with broad frequency queries ("What objects appear in bedrooms?"), then drill into co-occurrences ("Which objects appear with bed?"), cross-class distinctions ("What distinguishes bedroom from living room?"), and counterfactuals ("What if bed were absent?"). This facilitates the step-by-step reasoning process essential for effective model understanding.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Bridges expertise gaps:</b> Safety engineers and medical practitioners can query model behavior without SQL or programming knowledge.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>By eliminating the need for SQL or programming expertise, GLARE makes rigorous global explanations accessible to domain experts who are not ML practitioners. A safety engineer can ask "Does the model ever rely on background features for classification?" and receive a precise, data-grounded answer.</p>
                </div>
            </div>
            <div class="dropdown-item">
                <div class="dropdown-header">
                    <span class="header-text">
                        <b>Scalable to new domains:</b> Deploy on any new dataset by providing entity names&mdash;no retraining, no manual annotation.
                    </span>
                    <span class="icon">
                        <i class="fas fa-chevron-down"></i>
                    </span>
                </div>
                <div class="dropdown-content">
                    <p>The synthetic training pipeline and fence-based loss masking ensure the model learns SQL structure, not dataset-specific vocabulary. Deploying on a new domain requires only providing the entity name list and a database conforming to the same schema. The 90.6% zero-shot transfer to Pascal VOC demonstrates this is practical, not theoretical.</p>
                </div>
            </div>
        </div>

      </div>
    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @inproceedings{glare2026,
        title={GLARE: A Natural Language Interface for Querying Global Explanations},
        author={Anonymous Authors},
        booktitle={Under Review},
        year={2026}
      }
</code></pre>
  </div>
</section>


<script src="./static/js/bulma-carousel.min.js"></script>
<script src="./static/js/bulma-slider.min.js"></script>
<script src="./static/js/index.js"></script>

<script>
$(document).ready(function() {

    // Individual Dropdown Toggle
    $('.dropdown-header').click(function() {
        $(this).toggleClass('active');
        var content = $(this).next('.dropdown-content');
        content.slideToggle(200);
    });

    // Section Toggle
    $('.section-toggle').click(function(e) {
        e.preventDefault();
        e.stopPropagation();

        var section = $(this).closest('.section-container');
        var headers = section.find('.dropdown-header');
        var contents = section.find('.dropdown-content');
        var action = $(this).data('action');

        if (action === 'expand') {
            headers.addClass('active');
            contents.slideDown(200);
            $(this).text('[Collapse All]');
            $(this).data('action', 'collapse');
        } else {
            headers.removeClass('active');
            contents.slideUp(200);
            $(this).text('[Expand All]');
            $(this).data('action', 'expand');
        }
    });

    // Global Toggle
    $('#global-toggle').click(function() {
        var globalAction = $(this).data('action');
        var allSectionToggles = $('.section-toggle');

        allSectionToggles.each(function() {
            var currentSectionAction = $(this).data('action');
            if (globalAction === 'expand' && currentSectionAction === 'expand') {
                $(this).click();
            } else if (globalAction === 'collapse' && currentSectionAction === 'collapse') {
                $(this).click();
            }
        });

        if (globalAction === 'expand') {
            $(this).text('Collapse All Sections');
            $(this).data('action', 'collapse');
        } else {
            $(this).text('Expand All Sections');
            $(this).data('action', 'expand');
        }
    });

});
</script>

</body>
</html>
